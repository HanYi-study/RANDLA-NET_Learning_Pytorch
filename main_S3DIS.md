# main_S3DIS.pyæ–‡ä»¶è§£æ
---
## å°šæœªè§£å†³çš„é—®é¢˜ï¼š  
1. å¦‚æœé€‰æ‹©Area5ç”¨ä½œæµ‹è¯•é›†ï¼Œé‚£ä¸ºä»€ä¹ˆè®­ç»ƒçš„ç»“æœä¸­ç”Ÿæˆçš„æ—¥å¿—åªæœ‰Area5ï¼Œå¹¶ä¸”æµ‹è¯•ç»“æœä¸­ä¹Ÿæ˜¯åªæœ‰Area5ã€‚æ˜¯å¦å“ªé‡Œçš„è®¾å®šæœ‰é—®é¢˜ï¼Ÿç­”ï¼šè®­ç»ƒå’Œæµ‹è¯•æ—¥å¿—éƒ½åªæ¶‰åŠ Area_5ï¼Œè¿™é€šå¸¸ä¸æ˜¯æ ‡å‡†çš„ S3DIS 6-fold äº¤å‰éªŒè¯æµç¨‹ã€‚ä½†æ˜¯æ²¡æœ‰é—®é¢˜ï¼Œé¡¹ç›®æŒ‡å®šã€‚
2. ä»€ä¹ˆæ˜¯cfgï¼Ÿå¥½åƒæ˜¯ä¸€ä¸ªæ–‡ä»¶è®°è½½äº†é…ç½®æ•°æ®ï¼šæ˜¯çš„ï¼Œè®°è½½äº†å„ç§è¶…å‚æ•°ï¼ˆå¦‚è®­ç»ƒå‚æ•°ã€æ¨¡å‹ç»“æ„å‚æ•°ã€æ•°æ®å‚æ•°ã€æµ‹è¯•/éªŒè¯å‚æ•°ã€å…¶ä»–å‚æ•°ï¼‰
3. ä¼˜åŒ–å™¨Adamè¯¦ç»†äº†è§£ï¼ŒåŒ…å«äº†å“ªäº›å‚æ•°ï¼šï¼ˆAdaptive Moment Estimationï¼‰æ˜¯æ·±åº¦å­¦ä¹ ä¸­éå¸¸å¸¸ç”¨çš„è‡ªé€‚åº”ä¼˜åŒ–å™¨ï¼Œèƒ½åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶å®ç°è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´å’Œæ¢¯åº¦ä¸€é˜¶ã€äºŒé˜¶çŸ©çš„ä¼°è®¡ã€‚ï¼ˆå‚æ•°ï¼šlearning rate/å­¦ä¹ ç‡ï¼šæ§åˆ¶æ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥å¹…å¤§å°ã€‚beta1/ä¸€é˜¶çŸ©æ¢¯åº¦å‡å€¼ï¼‰çš„æŒ‡æ•°è¡°å‡ç‡ï¼Œå†³å®šâ€œåŠ¨é‡â€éƒ¨åˆ†çš„å¹³æ»‘ç¨‹åº¦ã€‚beta2/äºŒé˜¶çŸ©ï¼ˆæ¢¯åº¦å¹³æ–¹å‡å€¼ï¼‰çš„æŒ‡æ•°è¡°å‡ç‡ï¼Œå†³å®šâ€œè‡ªé€‚åº”å­¦ä¹ ç‡â€éƒ¨åˆ†çš„å¹³æ»‘ç¨‹åº¦ã€‚epsilonï¼ˆÏµï¼‰æ˜¯é˜²æ­¢åˆ†æ¯ä¸ºé›¶çš„å°å¸¸æ•°ï¼Œæå‡æ•°å€¼ç¨³å®šæ€§ã€‚weight_decayï¼ˆæƒé‡è¡°å‡/L2æ­£åˆ™åŒ–ï¼‰æ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå¹¶éæ‰€æœ‰Adamå®ç°éƒ½æœ‰æ­¤å‚æ•°ï¼Œå¦‚PyTorchæ”¯æŒï¼ŒKerasçš„Adamæ²¡æœ‰ç›´æ¥çš„weight_decayå‚æ•°ã€‚amsgradï¼šæ˜¯å¦å¯ç”¨AMSGradå˜ä½“ï¼Œèƒ½é¿å…æŸäº›æƒ…å†µä¸‹Adamæ”¶æ•›æ€§é—®é¢˜ã€‚
4. å­¦ä¹ ç‡çš„å¤§å°å¯¹æ¨¡å‹æ”¶æ•›ç¨‹åº¦çš„å½±å“æ˜¯ä»€ä¹ˆï¼Ÿ
   - å­¦ä¹ ç‡å¤ªå¤§æ—¶ï¼šå‚æ•°æ›´æ–°çš„æ¯ä¸€æ­¥éƒ½å®å¾—å¤ªå¤§ï¼Œå®¹æ˜“å¯¼è‡´æ¨¡å‹åœ¨æœ€ä¼˜è§£é™„è¿‘æ¥å›éœ‡è¡ï¼Œç”šè‡³å‘æ•£æ— æ³•æ”¶æ•›ã€‚æŸå¤±å‡½æ•°å¯èƒ½ä¸Šä¸‹æ³¢åŠ¨ï¼Œä¸ä¸‹é™ï¼Œæ¨¡å‹æ€§èƒ½ä¸ç¨³å®šã€‚ä¸»è¦è¡¨ç°ä¸ºæŸå¤±å€¼lossæ›²çº¿å‰§çƒˆæ³¢åŠ¨ï¼Œè®­ç»ƒè¿Ÿè¿Ÿä¸æ”¶æ•›ã€‚
   - å­¦ä¹ ç‡è¿‡å°æ—¶ï¼šæ¯æ¬¡å‚æ•°æ›´æ–°å¾ˆå°ï¼Œæ¨¡å‹æ”¶æ•›é€Ÿåº¦éå¸¸æ…¢ï¼Œè®­ç»ƒæ—¶é—´å¤§å¹…å¢åŠ ï¼Œå¯èƒ½ç°å¦‚å±€éƒ¨æœ€ä¼˜ï¼Œæˆ–è€…åœ¨éç‚¹ç­‰åŒºåŸŸåœæ»ä¸å‰ã€‚è¡¨ç°ä¸ºæŸå¤±å€¼ç¼“æ…¢ä¸‹é™ï¼Œç”šè‡³æå‰åœæ»ï¼Œæ¨¡å‹æ”¶æ•›æ•ˆç‡ä½ã€‚
   - åˆé€‚çš„å­¦ä¹ ç‡å¯ä»¥ä½¿æ¨¡å‹åœ¨åˆç†æ—¶é—´å†…å¹³ç¨³æ”¶æ•›åˆ°æœ€ä¼˜è§£ï¼ŒæŸå¤±å€¼ç¨³å®šä¸‹é™ï¼Œæœ€åè¶‹äºæ”¶æ•›ã€‚
   - å»ºè®®ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ç­–ç•¥æˆ–è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–å™¨ï¼ˆAdamç­‰ï¼‰æå‡è®­ç»ƒæ•ˆæœã€‚
5. ä¿®æ”¹S3DISæ•°æ®é›†Stanford3dDataset_v1.2_Aligned_Versionçš„åœ¨main_S3DIS.pyå’Œtest_S3DIS.pyçš„è¯»å–è·¯å¾„ä¸ºï¼š"Y:\projects\data\data_S3DIS\Stanford3dDataset_v1.2_Aligned_Version"(è¿˜æ²¡æœ‰ä¿®æ”¹ç¬¬äºŒä¸ªdataæ–‡ä»¶å¤¹çš„åå­—ä¸ºdata_S3DISï¼Œç­‰æ•°æ®é›†å¤åˆ¶ç»“æŸå†é‡å‘½åï¼‰
---
## ä¸»ä½“åŠŸèƒ½æ¦‚è§ˆï¼š  
è¯¥è„šæœ¬æ˜¯ RandLA-Net åœ¨ S3DIS æ•°æ®é›†ä¸Šçš„è®­ç»ƒä¸éªŒè¯ä¸»ç¨‹åºï¼Œä¸»è¦å®Œæˆï¼š

- S3DIS æ•°æ®åŠ è½½ä¸è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†ï¼ˆLeave-One-Outï¼‰
- ç½‘ç»œç»“æ„åˆå§‹åŒ–ä¸ checkpoint åŠ è½½
- å®Œæ•´è®­ç»ƒ + è¯„ä¼°å¾ªç¯ï¼ˆè®°å½•æœ€ä¼˜ mIoUï¼‰
- æ—¥å¿—ä¸æ¨¡å‹ä¿å­˜åŠŸèƒ½

---

##  ä¸»ä½“æ¨¡å—åˆ†è§£ï¼š

### ä¸€ã€ Argument å‚æ•°è§£æ

```python
parser = argparse.ArgumentParser()
# ä¸»è¦æ§åˆ¶è®­ç»ƒè®¾å¤‡ã€æœ€å¤§è½®æ•°ã€ä¿å­˜è·¯å¾„ã€éªŒè¯åŒºåŸŸï¼ˆareaï¼‰ï¼Œç”¨äºä»å‘½ä»¤å¥½æ¥å—å‚æ•°è¾“å…¥  
parser.add_argument('--checkpoint_path', default=None, help='Model checkpoint path [default: None]')
# æŒ‡å®šæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„ checkpointæ–‡ä»¶è·¯å¾„ã€‚å¦‚æœå¡«äº†è¯¥è·¯å¾„ï¼Œè®­ç»ƒå°†ä»è¯¥ checkpoint æ¢å¤ï¼ˆå³æ–­ç‚¹ç»­è®­ï¼‰ã€‚defaultæ˜¯é»˜è®¤å€¼ã€‚
parser.add_argument('--log_dir', default='train_output', help='Dump dir to save model checkpoint [default: log]')
# æŒ‡å®šæ—¥å¿—å’Œæ¨¡å‹ä¿å­˜æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œå…¶ä¸­åŒ…æ‹¬è®­ç»ƒæ—¥å¿—æ–‡ä»¶ã€æ¨¡å‹æƒé‡æ–‡ä»¶ç­‰ã€‚é»˜è®¤train_outputï¼ˆè¯¥æ–‡ä»¶å¤¹åœ¨æ–‡ä»¶ç»“æ„ä¸­å¯è§ï¼Œæ¯æ‰§è¡Œä¸€æ¬¡è¯¥æ–‡ä»¶å¤¹ä¸‹å°±ä¼šç”Ÿæˆä¸€æ¬¡æ‰§è¡Œæ—¥å¿—ä»¥åŠæ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œæ¨¡å‹æƒé‡æ–‡ä»¶å¯ç”¨äºtestæµ‹è¯•ä½¿ç”¨ï¼‰
parser.add_argument('--max_epoch', type=int, default=100, help='Epoch to run [default: 100]')
# æŒ‡å®šè®­ç»ƒçš„ æœ€å¤§ epoch æ•°ï¼Œå³è®­ç»ƒå°†å¾ªç¯å¤šå°‘è½®ã€‚é»˜è®¤100è½®ï¼Œå¯ä»¥é€šè¿‡train_outputä¸­7-12ç”Ÿæˆçš„è®­ç»ƒæ—¥å¿—çœ‹å‡ºï¼Œé»˜è®¤äº†100ä¸ªepochï¼ˆ0-99epochï¼‰ã€‚
parser.add_argument('--gpu', type=int, default=0, help='which gpu do you want to use [default: 0], -1 for cpu')
# æŒ‡å®šè®­ç»ƒä½¿ç”¨å“ªä¸€å—GPUï¼Œé»˜è®¤ä½¿ç”¨0å·GPUï¼Œè‹¥è¯¥å€¼è®¾ç½®ä¸º-1ï¼Œåˆ™ä½¿ç”¨cpuè¿›è¡Œè®­ç»ƒ
parser.add_argument('--test_area', type=int, default=5,help='Which area to use for test (others use to train), option: 1-6 [default: 5]')
# æŒ‡å®šé€‰ç”¨æ•°æ®é›†ä¸­å“ªä¸ªåŒºåŸŸç”¨ä½œæµ‹è¯•é›†ï¼Œå‰©ä¸‹å‡ ä¸ªéƒ½ç”¨äºè®­ç»ƒã€‚S3DISæ•°æ®é›†ä¸­å…±æœ‰6ä¸ªAreaï¼ˆåŒºåŸŸï¼‰ï¼Œé»˜è®¤ç¬¬äº”ä¸ªåŒºåŸŸç”¨ä½œæµ‹è¯•é›†ã€‚æ˜¯ä¸€ç§Leave-One-Outï¼ˆç•™ä¸€æ³•ï¼‰äº¤å‰éªŒè¯ã€‚
FLAGS = parser.parse_args()
# å°†ä¸Šè¿°æ‰€æœ‰å®šä¹‰çš„å‘½ä»¤è¡Œå‚æ•°è§£ææˆä¸€ä¸ªå¯¹è±¡FLAGSï¼Œå…¶å±æ€§ï¼šFLAGS.checkpoint_path  # è®¿é—®æ¨¡å‹è·¯å¾„/FLAGS.log_dir # è®¿é—®æ—¥å¿—è¾“å‡ºç›®å½•/FLAGS.max_epoch # æœ€å¤§è®­ç»ƒè½®æ•°/FLAGS.gpu # ä½¿ç”¨GPUç¼–å·/FLAGS.test_area # S3DISä¸­æµ‹è¯•åŒºåŸŸç¼–å·

```

- `--checkpoint_path`: æ¢å¤è®­ç»ƒæ—¶ç”¨çš„æ¨¡å‹è·¯å¾„ï¼ˆstringç±»å‹ï¼‰
- `--log_dir`: æ—¥å¿—ä¿å­˜æ–‡ä»¶å¤¹ï¼ˆå«æ—¶é—´æˆ³ï¼‰ï¼ˆstringç±»å‹ï¼‰
- `--max_epoch`: æœ€å¤§è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤100ï¼‰ï¼ˆintç±»å‹ï¼‰
- `--gpu`: ä½¿ç”¨å“ªå— GPUï¼ˆå¦‚ 0ï¼‰
- `--test_area`: ç•™å‡ºéªŒè¯åŒºåŸŸï¼ˆS3DIS Area1~6ï¼‰

---

### äºŒã€ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–

```python
#é¦–å…ˆï¼šåˆ›å»ºæ—¥å¿—ç›®å½•ä¸æ–‡ä»¶è·¯å¾„
LOG_DIR = FLAGS.log_dir
# ä»å‘½ä»¤è¡Œå‚æ•°ä¸­è¯»å–å¯¹è±¡FLAGSä¸­æ—¥å¿—å±æ€§log_dirçš„è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤æ˜¯train_outputï¼‰ï¼Œå¯ä»¥è¾“å…¥ä»è€Œå®ç°å°†è¿è¡Œæ—¥å¿—å’Œæƒé‡æ–‡ä»¶å­˜æ”¾è¿›æŒ‡å®šç›®å½•
LOG_DIR = os.path.join(LOG_DIR, time.strftime('%Y-%m-%d_%H-%M-%S', time.gmtime()))
# å°†LOG_DIRæ”¹æˆå¸¦æœ‰å½“å‰æ—¶é—´æˆ³çš„å­ç›®å½•
# ä½¿ç”¨time.gmtime() è·å–å½“å‰ GMT æ—¶é—´ï¼ˆå³æ ¼æ—å¨æ²»æ ‡å‡†æ—¶é—´ï¼‰
# time.strftime('%Y-%m-%d_%H-%M-%S', ...) æ ¼å¼åŒ–ä¸ºæ—¥æœŸå­—ç¬¦ä¸²
# è®­ç»ƒç»“æŸåç”Ÿæˆçš„æ—¥å¿—å’Œæ¨¡å‹æƒé‡æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹åç§°å¦‚ä¸‹ï¼š2025-07-12 01-48-28
# å¯ç¡®ä¿æ¯æ¬¡è¿è¡Œè®­ç»ƒæ—¶æ—¥å¿—ä¸ä¼šè¦†ç›–æ—§çš„ï¼Œè€Œæ˜¯ä¿å­˜åœ¨ä¸åŒçš„å¸¦æ—¶é—´æˆ³çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚
if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR)
# å¦‚æœä¸Šé¢æ‹¼æ¥å¾—åˆ°çš„è·¯å¾„è¿˜ä¸å­˜åœ¨ï¼Œå°±è‡ªåŠ¨åˆ›å»ºè¯¥å¤šçº§ç›®å½•ã€‚
# ä¿è¯åç»­æ–‡ä»¶ä¿å­˜ä¸ä¼šå› ç›®å½•ç¼ºå¤±æŠ¥é”™ã€‚

#å…¶æ¬¡ï¼šåˆ›å»ºæ—¥å¿—æ–‡ä»¶è·¯å¾„å¹¶æ‰“å¼€æ–‡ä»¶
log_file_name = f'log_train_Area_{FLAGS.test_area:d}.txt'
# æ„é€ æ—¥å¿—æ–‡ä»¶åï¼Œè¡¨ç¤ºå“ªä¸ªæµ‹è¯•åŒºåŸŸçš„è®­ç»ƒæ—¥å¿—ã€‚
# ç»è¿‡è®­ç»ƒä¹‹ååˆ›å»ºçš„æ–‡ä»¶åå¦‚ä¸‹ï¼šlog_train_Area_5.txt
LOG_FOUT = open(os.path.join(LOG_DIR, log_file_name), 'a')
# åœ¨åˆšæ‰åˆ›å»ºçš„æ—¥å¿—ç›®å½•ä¸­ï¼Œä»¥è¿½åŠ å†™å…¥ï¼ˆ'a'ï¼‰æ¨¡å¼æ‰“å¼€è¿™ä¸ªæ—¥å¿—æ–‡ä»¶ã€‚
# å¦‚æœä¸­é€”æ–­ç‚¹è®­ç»ƒï¼Œæ—¥å¿—æ–‡ä»¶ä»èƒ½æ¥ç€å†™ï¼Œä¸ä¼šè¦†ç›–ã€‚ä¹Ÿå¯ä»¥åœ¨è®­ç»ƒä¸­åŠ¨æ€ä¸æ–­å‘æ—¥å¿—æ–‡ä»¶å†™å…¥å†…å®¹ã€‚

#æœ€åï¼šæ—¥å¿—å†™å…¥å‡½æ•°
def log_string(out_str):
# è¿™æ˜¯ä¸€ä¸ªå°è£…å‡½æ•°ï¼Œç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç»Ÿä¸€è¾“å‡ºæ—¥å¿—ä¿¡æ¯ã€‚
# æ¯æ¬¡è°ƒç”¨log_string("æŸæ¡æ—¥å¿—")ï¼Œå°±ä¼šï¼š1.å†™å…¥.txtæ–‡ä»¶ 2.æ‰“å°åˆ°ç»ˆç«¯
    LOG_FOUT.write(out_str + '\n')
    LOG_FOUT.flush()
    print(out_str)

```

- è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„è®­ç»ƒæ—¥å¿—ç›®å½•
- `log_string()` å‡½æ•°ç”¨äºå†™æ—¥å¿—å¹¶æ‰“å°ä¿¡æ¯
- è¾“å‡ºæ—¥å¿—å¦‚ï¼š`train_output/2025-07-12_01-48-28/log_train_Area_5.txt`

---

### ä¸‰ã€ æ•°æ®é›†åŠ è½½ä¸åˆ’åˆ†

```python
# ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ•°æ®é›†å¯¹è±¡
dataset = S3DIS(FLAGS.test_area)
# åˆå§‹åŒ–S3DISæ•°æ®é›†ç±»å¯¹è±¡
# FLAGS.test_areaï¼šæŒ‡å®šç”¨äºæµ‹è¯•çš„åŒºåŸŸ
# S3DIS æ˜¯ä¸€ä¸ªå°è£…çš„æ•°æ®ç±»ï¼ˆé€šå¸¸å®šä¹‰åœ¨ s3dis_dataset.pyï¼‰ï¼šè¯»å–é¢„å¤„ç†è¿‡çš„ .txtã€.label æ–‡ä»¶/è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒå’ŒéªŒè¯é›†ï¼ˆä½¿ç”¨ç•™ä¸€éªŒè¯ç­–ç•¥ï¼‰/ä¿å­˜æ‰€æœ‰ç‚¹äº‘åæ ‡ã€é¢œè‰²ã€æ ‡ç­¾ç­‰åŸå§‹ä¿¡æ¯

# ç¬¬äºŒæ­¥ï¼šåˆ›å»ºè®­ç»ƒä¸éªŒè¯é‡‡æ ·å™¨
training_dataset = S3DISSampler(dataset, 'training')
validation_dataset = S3DISSampler(dataset, 'validation')
# S3DISSampler æ˜¯ç”¨äºé‡‡æ ·ç‚¹äº‘å—çš„å°è£…æ•°æ®é›†æ¥å£ç±»ï¼Œå°è£…äº† RandLA-Net çš„é‡‡æ ·é€»è¾‘ã€‚
# ç¬¬ä¸€ä¸ªå‚æ•°ï¼šdataset æ˜¯å‰é¢æ„é€ çš„å®Œæ•´ S3DIS æ•°æ®é›†å¯¹è±¡
# ç¬¬äºŒä¸ªå‚æ•°ï¼š'training'ï¼šä½¿ç”¨è®­ç»ƒåŒºåŸŸçš„æ•°æ®/'validation'ï¼šä½¿ç”¨æµ‹è¯•åŒºåŸŸçš„æ•°æ®ï¼ˆArea iï¼‰
# å¯¹ç‚¹äº‘å—è¿›è¡Œéšæœºé‡‡æ ·ï¼Œå®ç° RandLA-Net æ‰€éœ€çš„ å›ºå®šç‚¹æ•°é‡‡æ ·
# è¿”å›æ„é€ å¥½çš„è®­ç»ƒæ•°æ® batchï¼ŒåŒ…æ‹¬ï¼šxyz åæ ‡ã€colorsã€labelsã€neighborhood indices ç­‰å¼ é‡/collate_fn ç”¨äºè‡ªå®šä¹‰ batch æ‰“åŒ…æ–¹å¼ã€‚

# ç¬¬ä¸‰æ­¥ï¼šæ„å»ºPyTorch æ•°æ®åŠ è½½å™¨ï¼ˆDataLoaderï¼‰
training_dataloader = DataLoader(training_dataset, batch_size=cfg.batch_size, shuffle=True,collate_fn=training_dataset.collate_fn)
validation_dataloader = DataLoader(validation_dataset, batch_size=cfg.val_batch_size, shuffle=True,collate_fn=validation_dataset.collate_fn)
# ä¸ºè®­ç»ƒæ•°æ®æ„é€ æ‰¹å¤„ç†æ•°æ®æµ training_dataloader/ä¸ºæµ‹è¯•æ•°æ®æ„é€ æ‰¹å¤„ç†æ•°æ®æµ validation_dataloader
# training_dataset / validation_datasetï¼šä¸Šä¸€æ­¥ä¸­æ„é€ çš„é‡‡æ ·å™¨æ•°æ®é›† 
# batch_size	æ¯ä¸ª batch åŒ…å«çš„æ ·æœ¬æ•°é‡ï¼Œè®­ç»ƒé›†çš„æ ·æœ¬æ•°é‡æ¥è‡ªé…ç½® cfg.batch_sizeï¼ˆå¦‚ 6ï¼‰ï¼Œæµ‹è¯•é›†çš„æ ·æœ¬æ•°é‡æ¥è‡ªé…ç½®cfg.val_batch_sizeï¼ˆå³batchå¤§å°ä¸ºcfg.val_batch_sizeï¼‰
# shuffle=True	æ¯ä¸ª epoch éšæœºæ‰“ä¹±è®­ç»ƒæ ·æœ¬
# collate_fn	è‡ªå®šä¹‰æ‰¹å¤„ç†æ‰“åŒ…æ–¹æ³•ï¼Œç¡®ä¿ RandLA-Net èƒ½æ­£ç¡®è¯»å–æ¯ä¸€æ‰¹ç‚¹äº‘

# ç¬¬å››æ­¥ï¼šæ‰“å°æ•°æ®åŠ è½½å™¨ä¸­batchçš„æ•°é‡ï¼Œå…ˆè¾“å‡ºçš„æ˜¯è®­ç»ƒé›†batchæ•°é‡ï¼Œå†è¾“å‡ºæµ‹è¯•é›†çš„batchæ•°é‡ 
print(len(training_dataloader), len(validation_dataloader))
# æ‰“å°è®­ç»ƒå’ŒéªŒè¯é›†ä¸­æ€»çš„ batch æ•°é‡ï¼ˆå³ epoch ä¸­çš„è¿­ä»£æ¬¡æ•°ï¼‰
# è‹¥è¾“å‡ºæ˜¯620 156 / è®­ç»ƒé›†è¢«åˆ†ä¸º620ä¸ªbatchï¼ˆæ¯è½®è®­ç»ƒå°†è¿­ä»£620æ¬¡ï¼‰ / éªŒè¯é›†è¢«åˆ†ä¸º 156 ä¸ª batchï¼ˆæ¯è½®éªŒè¯å°†è¿­ä»£ 156 æ¬¡ï¼‰
```

- åŠ è½½å®Œæ•´ S3DIS ç‚¹äº‘åœºæ™¯æ•°æ®ï¼ˆåŒ…å«æ ‡ç­¾ï¼‰
- å°†é™¤æŒ‡å®š Area çš„å…¶ä½™åŒºåŸŸä½œä¸ºè®­ç»ƒé›†
- å°è£…æˆ `DataLoader`ï¼ˆå¸¦ batchã€éšæœºæ‰“ä¹±ã€collate_fnï¼‰

```text
æµç¨‹å›¾ï¼ˆç®€å•ç‰ˆï¼‰ï¼š
S3DIS Dataset        
     â†“
S3DISSampler (è®­ç»ƒ/éªŒè¯é‡‡æ ·)
     â†“
DataLoader (è®­ç»ƒ/éªŒè¯æ•°æ®åŠ è½½å™¨)
     â†“
ç”Ÿæˆ batched ç‚¹äº‘æ•°æ®ç”¨äºç½‘ç»œè¾“å…¥
```


####  è¾“å‡ºå˜é‡ï¼š
- `training_dataloader` ä¸­çš„ batch æ•°ï¼ˆå³è®­ç»ƒé›†ä¸­ä¸€å…±æœ‰å¤šå°‘ä¸ª batchï¼‰
- `validation_dataloader`ä¸­çš„ batch æ•°ï¼ˆå³éªŒè¯é›†ä¸­ä¸€å…±æœ‰å¤šå°‘ä¸ª batchï¼‰

---

### å››ã€ ç½‘ç»œæ„å»ºä¸åŠ è½½

```python
# ç¬¬ä¸€æ­¥ï¼šé€‰æ‹©è®¾å¤‡
if FLAGS.gpu >= 0:
# åˆ¤æ–­æ˜¯å¦æŒ‡å®šä½¿ç”¨ GPUï¼ˆå¯ä»¥é€šè¿‡é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ä¼ å…¥ --gpu=0 æˆ–å…¶ä»–å¤§äºç­‰äº 0 çš„å€¼ï¼Œå³FLAGS.gpuä¼ å…¥gpuå‚æ•°ï¼‰
    if torch.cuda.is_available():
    # å¦‚æœç³»ç»Ÿæ”¯æŒ CUDAï¼ˆå³å­˜åœ¨ GPU å¹¶å®‰è£…äº† CUDA é©±åŠ¨ï¼‰
        FLAGS.gpu = torch.device(f'cuda:{FLAGS.gpu:d}')
        # ä½¿ç”¨æŒ‡å®šç¼–å·çš„ GPUï¼Œè½¬æ¢ä¸º torch.device å¯¹è±¡
    else:
        warnings.warn('CUDA is not available on your machine. Running the algorithm on CPU.')
        # å¦‚æœç³»ç»Ÿæ²¡æœ‰å¯ç”¨gpuï¼Œåˆ™ä¼šç»™å‡ºè­¦å‘Š
        FLAGS.gpu = torch.device('cpu')
        # å¼ºåˆ¶ä½¿ç”¨cpu
else:
# è‹¥ä¸€å¼€å§‹ç»™å®šçš„å‚æ•°å°±æ˜¯-1ï¼Œåˆ™ç›´æ¥ä½¿ç”¨cpu
    FLAGS.gpu = torch.device('cpu')
device = FLAGS.gpu
# å°†è®¾å¤‡å¯¹è±¡èµ‹å€¼ç»™ deviceï¼Œåç»­ç»Ÿä¸€ä½¿ç”¨ device æ¥è¿ç§»ç½‘ç»œã€æ•°æ®ç­‰ï¼Œä¾¿äºç®¡ç†

# ç¬¬äºŒæ­¥ï¼šåˆå§‹åŒ–ç½‘ç»œç»“æ„å¹¶è¿ç§»åˆ°æŒ‡å®šè®¾å¤‡
net = Network(cfg)
# å®ä¾‹åŒ– RandLA-Net ç½‘ç»œç»“æ„å¯¹è±¡ï¼Œcfg åŒ…å«ç½‘ç»œå‚æ•°é…ç½®ï¼ˆé€šé“æ•°ã€å±‚æ•°ã€ç±»åˆ«æ•°ç­‰ï¼‰ã€‚
net.to(device)
# å°†æ¨¡å‹åŠ è½½åˆ°ç›®æ ‡è®¾å¤‡ä¸Šï¼ˆGPU æˆ– CPUï¼‰ï¼Œå¦åˆ™æ¨¡å‹æ— æ³•å‚ä¸è®­ç»ƒã€‚

# ç¬¬ä¸‰æ­¥ï¼šåˆå§‹åŒ–ä¼˜åŒ–å™¨
optimizer = optim.Adam(net.parameters(), lr=cfg.learning_rate)
# ä½¿ç”¨ Adam ä¼˜åŒ–å™¨
# net.parameters()ï¼šå¾…ä¼˜åŒ–çš„å‚æ•°
# cfg.learning_rateï¼šå­¦ä¹ ç‡ï¼Œæ¥è‡ªé…ç½®æ–‡ä»¶

# ç¬¬å››æ­¥ï¼šåˆå§‹åŒ–ç›¸å…³çŠ¶æ€å˜é‡
it = -1
# è®­ç»ƒè½®æ•°åˆå§‹åŒ–ä¸º-1
# ité€šå¸¸ç”¨äºå­¦ä¹ ç‡è°ƒåº¦å™¨
# itä¹Ÿç”¨äºæ‰¹å½’ä¸€åŒ–è°ƒåº¦å™¨ç­‰
start_epoch = 0
# è®­ç»ƒèµ·å§‹çš„epochæ˜¯0
# é»˜è®¤ä¸º0ï¼Œè‹¥ä¹‹ååŠ è½½äº†checkpointï¼Œå°†è¢«è¦†ç›–

# ç¬¬äº”æ­¥ï¼šåŠ è½½æ¨¡å‹æ–­ç‚¹ï¼ˆcheckpointï¼‰
CHECKPOINT_PATH = FLAGS.checkpoint_path
# ä»å‘½ä»¤è¡Œè¯»å–æ¨¡å‹æ–­ç‚¹è·¯å¾„ï¼ˆå¦‚æœæœ‰åˆ™è¯»å–0
if CHECKPOINT_PATH is not None and os.path.isfile(CHECKPOINT_PATH):
# åˆ¤æ–­æ˜¯å¦ä¼ å…¥äº†åˆæ³•çš„chechpointæ–‡ä»¶è·¯å¾„
    checkpoint = torch.load(CHECKPOINT_PATH)
    # åŠ è½½ checkpoint å†…å®¹ï¼Œæ˜¯ä¸€ä¸ªå­—å…¸å¯¹è±¡ï¼Œé€šå¸¸åŒ…å«å¦‚ä¸‹å‡ ç‚¹ï¼š
    # 1. model_state_dict:æ¨¡å‹å‚æ•°
    # 2. optimizer_state_dict:ä¼˜åŒ–å™¨çŠ¶æ€
    # 3. epoch:å·²è®­ç»ƒçš„è½®æ•° / æˆ–è€…è¿˜åŒ…å«å…¶ä»–å†…å®¹
    net.load_state_dict(checkpoint['model_state_dict'])
    # æ¢å¤ç½‘ç»œæƒé‡å‚æ•°ï¼Œç»§ç»­è®­ç»ƒ
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    # æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œä¾‹å¦‚å†å²åŠ¨é‡ã€å­¦ä¹ ç‡ç­‰
    start_epoch = checkpoint['epoch']
    # è®¾ç½®è®­ç»ƒå¼€å§‹çš„epochä¸ºæ–­ç‚¹æ–‡ä»¶ä¸­è®°å½•çš„å€¼ï¼Œç»§ç»­ä»epochå¼€å§‹ã€‚
    log_string("-> loaded checkpoint %s (epoch: %d)" % (CHECKPOINT_PATH, start_epoch))
    # æ‰“å°æ—¥å¿—ï¼Œæç¤ºæˆåŠŸåŠ è½½æ–­ç‚¹æ¨¡å‹
#ifä¸‹çš„æ‰€æœ‰æ“ä½œéƒ½æ˜¯åœ¨æœ‰æ–­ç‚¹çš„å‰æä¸‹æ‰§è¡Œçš„ï¼Œå¦‚æœæ²¡æœ‰æ–­ç‚¹åˆ™ä¸€æ¦‚ä¸æ‰§è¡Œ

```

- åˆå§‹åŒ– RandLA-Net æ¨¡å‹
- å°†æ¨¡å‹ç§»åŠ¨åˆ° CUDA æˆ– CPU ä¸Š
- è‹¥æä¾› checkpoint è·¯å¾„ï¼Œåˆ™æ¢å¤æ¨¡å‹ + ä¼˜åŒ–å™¨çŠ¶æ€

---

### äº”ã€ å­¦ä¹ ç‡è°ƒæ•´å‡½æ•°ï¼ˆè®­ç»ƒå‡½æ•°1ï¼‰

```python
def adjust_learning_rate(optimizer, epoch):
# æ ¹æ®å½“å‰çš„ epochï¼Œä½¿ç”¨é¢„è®¾çš„è¡°å‡ç³»æ•°å¯¹ä¼˜åŒ–å™¨ä¸­çš„å­¦ä¹ ç‡ lr è¿›è¡Œè°ƒæ•´
# è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸é™ä½å­¦ä¹ ç‡ï¼Œæå‡æ¨¡å‹æ”¶æ•›ç¨³å®šæ€§
# optimizer: å½“å‰ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼ˆå¦‚ Adamï¼‰
# epoch: å½“å‰è®­ç»ƒè½®æ¬¡ï¼ˆä» 0 å¼€å§‹ï¼‰
    lr = optimizer.param_groups[0]['lr']
    # ä»ä¼˜åŒ–å™¨ä¸­è·å–å½“å‰å­¦ä¹ ç‡lr
    # optimizer.param_groups æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º1çš„åˆ—è¡¨ï¼ˆå¯èƒ½æœ‰æ—¶ä¸ä¸ºä¸€ï¼‰ï¼Œåˆ—è¡¨é‡Œé¢æ˜¯å­—å…¸ï¼Œå­—å…¸ä¸­æœ‰è¯¥ä¼˜åŒ–å™¨ç›¸å…³çš„å‚æ•°ï¼Œé€šå¸¸åªåŒ…å«ä¸€ä¸ªå­—å…¸é¡¹ï¼ˆé™¤éä½ ä¸ºä¸åŒå±‚è®¾ç½®äº†ä¸åŒå­¦ä¹ ç‡ï¼‰
    # param_groups[0]['lr'] å³å½“å‰æ­£åœ¨ä½¿ç”¨çš„å­¦ä¹ ç‡å€¼
    lr = lr * cfg.lr_decays[epoch]
    # cfg.lr_decaysä¸€ä¸ªæœ‰500ä¸ªé”®å€¼å¯¹çš„å­—å…¸ï¼Œä¸ºæ¯ä¸€ä¸ª epoch é¢„å®šä¹‰äº†ä¸€ä¸ªè¡°å‡å› å­ï¼ˆå¦‚ 0.95ï¼‰ï¼Œæ¯ä¸ªé”®å¯¹åº”çš„å€¼éƒ½æ˜¯0.95ï¼ˆè¡°å‡å› å­ï¼‰ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªepochå­¦ä¹ ç‡è¡°å‡0.95
    # æ¯è½®è®­ç»ƒï¼Œå­¦ä¹ ç‡éƒ½ä¹˜ä¸Šè¯¥è½®å¯¹åº”çš„è¡°å‡ç³»æ•°
    # å®ç°äº†é€ epoch è¡°å‡å­¦ä¹ ç‡ç­–ç•¥
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
    # éå†ä¼˜åŒ–å™¨ä¸­æ‰€æœ‰å‚æ•°ç»„ï¼ˆé€šå¸¸å°±1ä¸ªï¼‰
    # å°†æ–°è®¡ç®—å‡ºçš„å­¦ä¹ ç‡lrèµ‹å€¼å›ä¼˜åŒ–å™¨
    # å®Œæˆå®é™…çš„å­¦ä¹ ç‡æ›´æ–°æ“ä½œï¼Œä½¿ä¸‹ä¸€è½®è®­ç»ƒä»¥æ–°çš„å­¦ä¹ ç‡è¿›è¡Œ
```

- æ¯ä¸ª epoch å­¦ä¹ ç‡ä¹˜ä»¥ `cfg.lr_decays[epoch]`
- é€šå¸¸æ˜¯æŒ‡æ•°è¡°å‡ï¼Œå¦‚ 0.95^epoch
- æœ€ç»ˆæ•ˆæœï¼šæ¯è®­ç»ƒä¸€ä¸ª epochï¼Œå°±å°†å½“å‰å­¦ä¹ ç‡ä¹˜ä¸Šä¸€ä¸ªè¡°å‡ç³»æ•°ï¼ˆå¦‚ 0.95ï¼‰ï¼Œå¦‚æœåˆå§‹ä¸º 0.01ï¼Œç¬¬ 1 è½®åå˜ä¸º 0.0095ï¼Œç¬¬ 2 è½®åå˜ä¸º 0.009025ï¼Œä¾æ­¤ç±»æ¨

---

### å…­ã€ è®­ç»ƒå•ä¸ª epoch å‡½æ•°ï¼š`train_one_epoch()` ï¼ˆè®­ç»ƒå‡½æ•°2ï¼‰

```python
def train_one_epoch():
# è®­ç»ƒä¸€ä¸ªepochï¼ˆå®Œæ•´çš„ä¸€è½®éå†è®­ç»ƒé›†ï¼‰
# å®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„ä¸»å‡½æ•°ï¼Œæ‰§è¡Œä¸€è½®å®Œæ•´çš„ forward + backward è¿‡ç¨‹
# é€šå¸¸ç”± train() ä¸»å‡½æ•°è°ƒç”¨
    stat_dict = {}  # collect statistics
    # ç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ª batch çš„ lossã€accuracyã€IoU ç­‰ç»Ÿè®¡é‡
    # æœ€ç»ˆç”¨äºæ—¥å¿—è¾“å‡º
    adjust_learning_rate(optimizer, EPOCH_CNT)
    # è°ƒç”¨å‡½æ•°è°ƒæ•´å½“å‰ epoch çš„å­¦ä¹ ç‡
    # EPOCH_CNT æ˜¯å½“å‰è®­ç»ƒè½®æ¬¡
    # å®ç°é€ epoch çš„å­¦ä¹ ç‡è¡°å‡ç­–ç•¥ï¼Œè°ƒç”¨äº†ä¸Šä¸€ä¸ªå®šä¹‰çš„å­¦ä¹ ç‡è¡°å‡å‡½æ•°
    net.train()
    # å°†æ¨¡å‹è®¾ç½®ä¸ºâ€œè®­ç»ƒæ¨¡å¼â€
    # å¯ç”¨ dropout å’Œ BatchNorm çš„è®­ç»ƒè¡Œä¸º
    iou_calc = IoUCalculator(cfg)
    # åˆå§‹åŒ–IOUè®¡ç®—å™¨
    # ç”¨äºåç»­ç»Ÿè®¡æ¯ä¸€ç±»ç‚¹çš„åˆ†å‰²æ•ˆæœ
    # cfg æä¾›ç±»åˆ«æ•°ç­‰é…ç½®ä¿¡æ¯

    # å¼€å§‹éå†è®­ç»ƒæ•°æ®ï¼ˆæŒ‰batchï¼‰
    for batch_idx, batch_data in enumerate(training_dataloader):
    # æšä¸¾è®­ç»ƒé›†ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡
    # batch_data æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«å¦‚ä¸‹é”®å€¼ï¼šxyz, features, labels, neighbors, subs, interp, ç­‰
        t_start = time.time()
        # è®°å½•å½“å‰ batch çš„å¼€å§‹æ—¶é—´ï¼Œç”¨äºç»Ÿè®¡å¤„ç†é€Ÿåº¦
        for key in batch_data:
            if type(batch_data[key]) is list:
                for i in range(len(batch_data[key])):
                    batch_data[key][i] = batch_data[key][i].to(device)
            else:
                batch_data[key] = batch_data[key].to(device)
        # é€’å½’åœ°å°† batch ä¸­çš„æ‰€æœ‰å¼ é‡è¿ç§»åˆ°ç›®æ ‡è®¾å¤‡ï¼Œå…¼å®¹åµŒå¥— list ç±»å‹æ•°æ®ç»“æ„

        # å‰å‘ä¼ æ’­ä¸åå‘ä¼ æ’­ï¼ˆæ¯ä¸ªbatchéƒ½è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­+åå‘ä¼ æ’­ï¼‰
        optimizer.zero_grad()
        # æ¸…ç©ºä¸Šä¸€æ­¥ä¸­çš„æ¢¯åº¦ç¼“å­˜ï¼Œé˜²æ­¢æ¢¯åº¦ç´¯ç§¯
        end_points = net(batch_data)
        # è°ƒç”¨ RandLA-Net ç½‘ç»œçš„ forward() æ–¹æ³• / å‰å‘ä¼ æ’­
        # è¾“å…¥æ˜¯ batch_dataï¼Œè¾“å‡ºæ˜¯é¢„æµ‹ç»“æœåŠä¸­é—´å€¼å­—å…¸ end_points
        loss, end_points = compute_loss(end_points, cfg, device)
        # è®¡ç®—æŸå¤±å€¼ï¼ˆå¦‚äº¤å‰ç†µæŸå¤±ï¼‰ï¼Œå¹¶é™„åŠ åˆ° end_points ä¸­
        loss.backward()
        # åå‘ä¼ æ’­ï¼Œè®¡ç®—æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦
        optimizer.step()
        # ä½¿ç”¨ä¼˜åŒ–å™¨ï¼ˆå¦‚ Adamï¼‰æ›´æ–°æ¨¡å‹å‚æ•°

        # è®¡ç®—ç²¾åº¦ + ç´¯è®¡IoU
        acc, end_points = compute_acc(end_points)
        # è®¡ç®—æœ¬batchçš„å‡†ç¡®ç‡ï¼Œå¹¶æ›´æ–°end_points
        iou_calc.add_data(end_points)
        # ä¿å­˜é¢„æµ‹å’Œæ ‡ç­¾ä¿¡æ¯ï¼Œç”¨äºåç»­ batch ç»Ÿä¸€è®¡ç®— IoU

        # ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
        for key in end_points:
            if 'loss' in key or 'acc' in key or 'iou' in key:
                if key not in stat_dict: stat_dict[key] = 0
                stat_dict[key] += end_points[key].item()
        # å°†æ¯ä¸€ batch çš„ç»Ÿè®¡é‡ï¼ˆlossã€accï¼‰ç´¯åŠ ï¼Œä¾¿äºè¾“å‡ºå¹³å‡å€¼

        # æ¯ N ä¸ª batch è¾“å‡ºä¸€æ¬¡æ—¥å¿—
        batch_interval = 50  
        if (batch_idx + 1) % batch_interval == 0:
            t_end = time.time()
        # è®¾ç½®é—´éš” batch_interval=50ï¼Œæ¯å¤„ç† 50 ä¸ª batch è¾“å‡ºä¸€æ¬¡ä¸­é—´ç»“æœã€‚
            # log_string(' ---- batch: %03d ----' % (batch_idx + 1))
            # # TRAIN_VISUALIZER.log_scalars({key:stat_dict[key]/batch_interval for key in stat_dict},
            # #     (EPOCH_CNT*len(TRAIN_DATALOADER)+batch_idx)*BATCH_SIZE)
            # for key in sorted(stat_dict.keys()):
            #     log_string('mean %s: %f' % (key, stat_dict[key] / batch_interval))
            #     stat_dict[key] = 0
            log_string('Step %03d Loss %.3f Acc %.2f lr %.5f --- %.2f ms/batch' % (batch_idx + 1,stat_dict['loss'] / batch_interval,stat_dict['acc'] / batch_interval,optimizer.param_groups[0]['lr'],1000 *(t_end - t_start)))
            # è¾“å‡ºï¼šå½“å‰ step çš„å¹³å‡ lossã€accuracyã€å­¦ä¹ ç‡ã€æ¯ batch è€—æ—¶ï¼ˆmsï¼‰
            # è°ƒç”¨äº†å°è£…çš„ log_string() å‡½æ•°ï¼Œæ”¯æŒæ–‡ä»¶å†™å…¥ + æ§åˆ¶å°è¾“å‡º
            stat_dict['loss'], stat_dict['acc'] = 0, 0
            # æ¯è¾“å‡ºä¸€æ¬¡ï¼Œå°±æ¸…ç©º loss å’Œ acc ç´¯ç§¯å€¼ï¼Œå‡†å¤‡ç»Ÿè®¡ä¸‹ä¸€ä¸ª batch_interval

    # ç°åœ¨æ•´ä¸ªepochä¸­æ‰€æœ‰çš„batchéƒ½éå†ç»“æŸï¼ˆåªè¿›è¡Œäº†ä¸€ä¸ªepochï¼‰
    mean_iou, iou_list = iou_calc.compute_iou()
    # æ±‡æ€»æ•´ä¸ª epoch çš„æ‰€æœ‰é¢„æµ‹ä¸æ ‡ç­¾ï¼Œè®¡ç®—æ¯ä¸€ç±»çš„ IoU åŠå¹³å‡å€¼
    log_string('mean IoU:{:.1f}'.format(mean_iou * 100))
    # è¾“å‡ºå¹³å‡ IoUï¼ˆä¿ç•™ 1 ä½å°æ•°ï¼‰ï¼Œå•ä½ä¸º %ï¼Œè¿™æ˜¯ä¸€ä¸ªepochæ‰€æœ‰ç±»çš„IoUæ‰€å–çš„å¹³å‡å€¼
    s = 'IoU:'
    for iou_tmp in iou_list:
        s += '{:5.2f} '.format(100 * iou_tmp)
    log_string(s)
    # è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„ IoU å€¼ï¼Œä¿ç•™ 2 ä½å°æ•°ï¼Œå•ä½ä¸º %

```

#### åŠŸèƒ½ï¼š
- è®­ç»ƒçŠ¶æ€è®¾ä¸º `net.train()`
- éå†æ‰€æœ‰è®­ç»ƒ batchï¼š
  - è¾“å…¥æ•°æ®é€å…¥æ¨¡å‹ï¼Œè¾“å‡º `end_points`
  - è®¡ç®— `loss` â†’ åå‘ä¼ æ’­ â†’ ä¼˜åŒ–å™¨æ›´æ–°
  - ç´¯åŠ  `loss`ã€`acc`ã€æ·»åŠ åˆ° IoU è®¡ç®—å™¨
- æ¯ 50 ä¸ª batch è¾“å‡ºä¸€æ¬¡è®­ç»ƒç»Ÿè®¡ä¿¡æ¯
- æœ€åè¾“å‡ºæ•´ä¸ª epoch çš„ `mean IoU` å’Œ per-class `IoU`

#### è¾“å…¥ï¼š
- `training_dataloader`, `net`, `optimizer`, `cfg`, `device`

---

### ä¸ƒã€ è¯„ä¼°å‡½æ•°ï¼š`evaluate_one_epoch()`ï¼ˆè®­ç»ƒå‡½æ•°3ï¼‰

```python
def evaluate_one_epoch():
# ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½ï¼Œæ‰§è¡Œä¸€è½®å®Œæ•´çš„æ¨ç†æµç¨‹ï¼Œè¾“å‡º lossã€accuracyã€IoU ç­‰æŒ‡æ ‡ã€‚ä¸ä¼šæ›´æ–°æ¨¡å‹æƒé‡ï¼ˆå³ä¸è¿›è¡Œè®­ç»ƒï¼‰
    stat_dict = {}  
    # åˆå§‹åŒ–ç”¨äºæ”¶é›†éªŒè¯è¿‡ç¨‹ä¸­ç»Ÿè®¡æ•°æ®ï¼ˆå¦‚lossã€accuracyã€iouï¼‰
    net.eval()  
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­Dropoutå’ŒBatchNormçš„è®­ç»ƒè¡Œä¸ºï¼‰
    iou_calc = IoUCalculator(cfg)
    # åˆå§‹åŒ–IoUè®¡ç®—å™¨ï¼Œç”¨äºç»Ÿè®¡æ¯ç±»çš„äº¤å¹¶æ¯”æŒ‡æ ‡
    for batch_idx, batch_data in enumerate(validation_dataloader):
    # éå†éªŒè¯é›†æ¯ä¸ªbatch
        for key in batch_data:
        # å°†batchä¸­çš„æ‰€æœ‰æ•°æ®è¿ç§»åˆ°GPUæˆ–CPUï¼ˆæ ¹æ®é…ç½®ï¼‰
            if type(batch_data[key]) is list:
            # å¤„ç†åˆ—è¡¨ç±»å‹ï¼ˆå¤šå±‚ç‰¹å¾ï¼‰
                for i in range(len(batch_data[key])):
                    batch_data[key][i] = batch_data[key][i].to(device)
            else:
                batch_data[key] = batch_data[key].to(device)

        # å‰å‘ä¼ æ’­ï¼ˆéªŒè¯é˜¶æ®µå…³é—­æ¢¯åº¦è®¡ç®—ä»¥èŠ‚çœæ˜¾å­˜ï¼‰
        with torch.no_grad():
            end_points = net(batch_data)
            # è¾“å…¥batchç‚¹äº‘ï¼Œè¾“å‡ºé¢„æµ‹ç»“æœå’Œä¸­é—´å˜é‡

        # è®¡ç®—lossï¼ˆä¸€èˆ¬ä¸ºäº¤å‰ç†µï¼‰ï¼Œç”¨äºè¡¡é‡é¢„æµ‹ä¸çœŸå€¼çš„å·®å¼‚
        loss, end_points = compute_loss(end_points, cfg, device)

        # è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡ï¼ˆå¦‚top1 accï¼‰
        acc, end_points = compute_acc(end_points)
        iou_calc.add_data(end_points)
        # ä¿å­˜é¢„æµ‹ä¸æ ‡ç­¾ï¼Œç”¨äºåç»­è®¡ç®—IoU

        # ç´¯åŠ å„ç±»ç»Ÿè®¡é‡ï¼ˆlossã€accç­‰ï¼‰ä»¥è®¡ç®—å¹³å‡å€¼
        for key in end_points:
            if 'loss' in key or 'acc' in key or 'iou' in key:  # æ²¡æœ‰iouä¸€é¡¹ï¼Œiouåœ¨ä¸‹é¢è®¡ç®—
                if key not in stat_dict: stat_dict[key] = 0
                stat_dict[key] += end_points[key].item()

    # éå†ç»Ÿè®¡ç»“æœå¹¶è¾“å‡ºæ¯é¡¹å¹³å‡å€¼
    for key in sorted(stat_dict.keys()):
        log_string('eval mean %s: %f' % (key, stat_dict[key] / (float(batch_idx + 1))))

    # è®¡ç®—æ•´ä½“IoUä¸æ¯ä¸€ç±»çš„IoU
    mean_iou, iou_list = iou_calc.compute_iou()

    # è¾“å‡ºå¹³å‡IoU
    log_string('mean IoU:{:.1f}%'.format(mean_iou * 100))
    log_string('--------------------------------------------------------------------------------------')

    # è¾“å‡ºæ¯ä¸€ç±»çš„IoUå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
    s = f'{mean_iou * 100:.1f} | '
    for iou_tmp in iou_list:
        s += '{:5.2f} '.format(100 * iou_tmp)
    log_string(s)
    log_string('--------------------------------------------------------------------------------------')
    return mean_iou   # è¿”å›è¯¥è½®éªŒè¯çš„å¹³å‡IoUç”¨äºä¿å­˜æœ€ä¼˜æ¨¡å‹ç­‰é€»è¾‘
```

#### åŠŸèƒ½ï¼š
- è®¾ç½®ä¸º `net.eval()`ï¼ˆç¦ç”¨ Dropout å’Œ BN æ›´æ–°ï¼‰
- åªè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œä¸è¿›è¡Œåå‘ä¼ æ’­
- ç»Ÿè®¡éªŒè¯é›†ä¸Šçš„ `loss`ã€`acc`ã€`IoU`
- evaluate_one_epoch() ä¼šè¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ï¼Œè¾“å‡º lossã€acc å’Œ mean IoUï¼Œä¸æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä»…ç”¨äºç›‘æ§æ¨¡å‹è®­ç»ƒè´¨é‡

#### è¾“å‡ºï¼š
- è¿”å› `mean_iou`ï¼ˆfloatï¼‰ï¼Œå½“å‰éªŒè¯é›†ä¸Šçš„ å¹³å‡ IoU å€¼ï¼ŒèŒƒå›´ 0~1

#### æµç¨‹æ­¥éª¤ï¼š
- åˆå§‹åŒ–ï¼šstat_dict è®°å½• lossã€acc ç´¯ç§¯å€¼ï¼›net.eval() è®¾ç½®æ¨¡å‹è¯„ä¼°æ¨¡å¼ï¼›åˆ›å»º IoU è®¡ç®—å™¨
- éå†éªŒè¯é›†ï¼šä½¿ç”¨ enumerate(validation_dataloader) æ‰¹é‡è¯»å–éªŒè¯ç‚¹äº‘æ•°æ®
- æ•°æ®è¿ç§»è®¾å¤‡ï¼šå°†æ¯ä¸ª batch ä¸­çš„æ•°æ®è¿ç§»åˆ° GPU/CPU
- å‰å‘ä¼ æ’­ï¼šå…³é—­æ¢¯åº¦è®¡ç®—ï¼Œç”¨ net(batch_data) è¿›è¡Œæ¨ç†
- è®¡ç®— lossï¼šä½¿ç”¨ compute_loss() å¾—åˆ°å½“å‰ batch çš„æŸå¤±å€¼
- è®¡ç®— accï¼šä½¿ç”¨ compute_acc() å¾—åˆ°å½“å‰ batch çš„å‡†ç¡®ç‡
- æ›´æ–° IoU çŠ¶æ€ï¼šæŠŠé¢„æµ‹å’Œæ ‡ç­¾äº¤ç»™ IoUCalculator åšç´¯ç§¯ç»Ÿè®¡
- ç´¯è®¡ç»Ÿè®¡ä¿¡æ¯ï¼šå°† lossã€acc ç»“æœåŠ å…¥ stat_dict
- è¾“å‡ºå¹³å‡ç»“æœï¼šéå† stat_dict è¾“å‡ºå¹³å‡ loss/acc ç­‰æŒ‡æ ‡
- è®¡ç®—å¹¶è¾“å‡º IoUï¼šä½¿ç”¨ IoUCalculator.compute_iou() å¾—åˆ° mean IoU å’Œæ¯ç±» IoU
- è¿”å›ç»“æœï¼šè¿”å› mean IoUï¼Œä¾›å¤–éƒ¨è°ƒç”¨åˆ¤æ–­æ˜¯å¦ä¿å­˜ checkpoint æ¨¡å‹

---

### å…«ã€ è®­ç»ƒä¸»æ§å‡½æ•°ï¼š`train(start_epoch)`ï¼ˆè®­ç»ƒå‡½æ•°4ï¼‰

```python
def train(start_epoch):
# å®šä¹‰è®­ç»ƒå‡½æ•°ï¼Œä¼ å…¥èµ·å§‹ epoch
    global EPOCH_CNT
    # å£°æ˜ EPOCH_CNT æ˜¯å…¨å±€å˜é‡ï¼Œè¡¨ç¤ºå½“å‰è®­ç»ƒçš„ epoch ç¼–å·ã€‚
    loss = 0
    now_miou = 0
    max_miou = 0
    # åˆå§‹åŒ– loss ç´¯è®¡å€¼ã€å½“å‰ epoch çš„ mIoUã€å†å²æœ€ä¼˜ mIoU
    for epoch in range(start_epoch, FLAGS.max_epoch):
    # å¼€å§‹ä» start_epoch è®­ç»ƒåˆ°è®¾ç½®çš„æœ€å¤§ epoch æ•°ï¼ˆé»˜è®¤ 100ï¼‰    ç°åœ¨æ˜¯æŒ‰ç…§epochç¼–å·éå†ï¼Œä¹‹å‰é‚£ä¸ªone_epochå‡½æ•°æ˜¯ä¸€ä¸ªepochä¸­nä¸ªbatchè¿›è¡Œéå†
        EPOCH_CNT = epoch
        # æ›´æ–°å…¨å±€å˜é‡ EPOCH_CNTï¼Œä¾›å…¶ä»–å‡½æ•°å¦‚ adjust_learning_rate() ä½¿ç”¨
        log_string('**** EPOCH %03d ****' % (epoch))
        log_string(str(datetime.now()))
        # æ‰“å°å½“å‰ epoch ç¼–å·å’Œå½“å‰æ—¶é—´æˆ³ï¼ˆUTCæ—¶é—´ï¼‰ï¼Œè®°å½•æ—¥å¿—
        np.random.seed()
        # é‡ç½® NumPy çš„éšæœºç§å­ï¼Œä¿è¯æ¯æ¬¡ epoch æ•°æ®éšæœºé‡‡æ ·ä¸åŒã€‚
        train_one_epoch()
        # æ‰§è¡Œä¸€ä¸ª epoch çš„è®­ç»ƒé€»è¾‘ï¼Œè®¡ç®— lossã€accã€IoU ç­‰ï¼ˆä¼šæ›´æ–°æ¨¡å‹æƒé‡ï¼‰

        # if EPOCH_CNT == 0 or EPOCH_CNT % 10 == 9: # Eval every 10 epochs
        log_string('**** EVAL EPOCH %03d START****' % (epoch))
        now_miou = evaluate_one_epoch()
        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å½“å‰æ¨¡å‹ï¼Œå¹¶è¿”å›å½“å‰ mean IoUï¼ˆç”¨äºæ¨¡å‹æ€§èƒ½åˆ¤æ–­ï¼‰

        # Save checkpoint
        if (now_miou > max_miou):  # ä¿å­˜æœ€å¥½çš„iouçš„æ¨¡å‹
        # å¦‚æœå½“å‰ mIoU æ¯”ä¹‹å‰æœ€ä½³æ›´é«˜ï¼Œè¯´æ˜æ¨¡å‹æ•ˆæœæ›´å¥½ï¼Œä¿å­˜ checkpoint
            save_dict = {'epoch': epoch + 1,  # after training one epoch, the start_epoch should be epoch+1
                         'optimizer_state_dict': optimizer.state_dict(),
                         'loss': loss,
                         }
            # å‡†å¤‡ä¸€ä¸ªåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ã€æŸå¤±ã€epoch çš„å­—å…¸ï¼Œç”¨äºæ¨¡å‹æ¢å¤è®­ç»ƒ
            try:  # with nn.DataParallel() the net is added as a submodule of DataParallel
                save_dict['model_state_dict'] = net.module.state_dict()
            # å¦‚æœæ¨¡å‹æ˜¯ DataParallel æ¨¡å¼ï¼Œä½¿ç”¨ .module è®¿é—®å®é™…æ¨¡å‹
            except:
                save_dict['model_state_dict'] = net.state_dict()
            # å¦åˆ™ç›´æ¥ä¿å­˜æ¨¡å‹æƒé‡ã€‚
            torch.save(save_dict, os.path.join(LOG_DIR, 'checkpoint.tar'))
            # å°†æƒé‡ä¿å­˜ä¸º checkpoint.tarï¼ˆæ¨¡å‹çš„æƒé‡æ–‡ä»¶ï¼‰
            max_miou = now_miou
            # æ›´æ–°æœ€ä¼˜ mIoUã€‚

        log_string('Best mIoU = {:2.2f}%'.format(max_miou * 100))
        log_string('**** EVAL EPOCH %03d END****' % (epoch))
        log_string('')
        # è®°å½•å½“å‰æœ€ä¼˜ mIoUï¼Œä»¥åŠè¯„ä¼°ç»“æŸçš„æ—¥å¿—ä¿¡æ¯

```

#### åŠŸèƒ½ï¼š
- æ§åˆ¶æ•´ä¸ªè®­ç»ƒæµç¨‹ï¼š
  - é€è½®è®­ç»ƒ (`train_one_epoch`)ï¼Œè¿›è¡Œå¤šä¸ª epoch çš„è®­ç»ƒ
  - æ¯è½®éªŒè¯ (`evaluate_one_epoch`)ï¼Œæ¯ä¸ª epoch åè¯„ä¼°ä¸€æ¬¡éªŒè¯é›†æ€§èƒ½ï¼ˆmIoUï¼‰
  - ä¿å­˜æœ€ä¼˜æ¨¡å‹ checkpointï¼ˆæŒ‰ mIoU é€‰ï¼‰ï¼Œè‹¥å½“å‰æ¨¡å‹ä¼˜äºä¹‹å‰æœ€ä¼˜è¡¨ç°ï¼ˆmax_miouï¼‰ï¼Œåˆ™ä¿å­˜ä¸º checkpoint

#### è¾“å…¥ï¼š
- å‚æ•°start_epochï¼ˆintç±»å‹ï¼‰ï¼šå¼€å§‹è®­ç»ƒçš„ epoch ç¼–å·ï¼ˆå¦‚æœä» checkpoint æ¢å¤åˆ™é 0ï¼‰

#### è¾“å‡ºï¼š
- æ—¥å¿—å†™å…¥ï¼Œè¾“å‡ºæ—¥å¿—æ–‡ä»¶ log_train_Area_*.txt
- æ¨¡å‹ä¿å­˜åˆ°ï¼š`checkpoint.tar`ï¼ˆæ— æ˜¾å¼è¿”å›å€¼ï¼Œå°†æœ€ä¼˜æ¨¡å‹æƒé‡ä¿å­˜ä¸º checkpoint.tarï¼‰

---

##  è„šæœ¬ä¸»å…¥å£

```python
if __name__ == '__main__':
    train(start_epoch)
```

- ä»¥æŒ‡å®š `start_epoch`ï¼ˆé»˜è®¤0ï¼‰å¼€å§‹è®­ç»ƒ

---

##  å…³é”®æ•°æ®ç»“æ„

| å˜é‡å           | ç±»å‹            | æè¿°                         |
|------------------|-----------------|------------------------------|
| `batch_data`     | dict[list/torch] | æ¯ä¸ª batch çš„ç‚¹äº‘å—ã€æ ‡ç­¾ç­‰   |
| `end_points`     | dict             | ç½‘ç»œè¾“å‡ºï¼ˆlossã€accã€é¢„æµ‹æ ‡ç­¾ï¼‰ |
| `iou_list`       | list[float]      | æ¯ç±»çš„ IoU å€¼                |
| `mean_iou`       | float            | æ‰€æœ‰ç±»åˆ«çš„å¹³å‡ IoU           |

---

##  æ ¸å¿ƒæµç¨‹å›¾ï¼ˆæ–‡å­—ç‰ˆï¼‰

```text
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ RandLA-Net è®­ç»ƒä¸»æµç¨‹ï¼ˆmain_S3DIS.pyï¼‰-----ç”±chatgptç”Ÿæˆç¾è§‚çš„æµç¨‹å›¾
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1ï¸âƒ£ å‚æ•°é…ç½® & æ—¥å¿—åˆå§‹åŒ–
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ argparse è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œç”Ÿæˆ FLAGS         â”‚
â”‚  - --checkpoint_pathï¼šæ¨¡å‹åŠ è½½è·¯å¾„          â”‚
â”‚  - --log_dirï¼šæ—¥å¿—è¾“å‡ºæ–‡ä»¶å¤¹                â”‚
â”‚  - --max_epochï¼šæœ€å¤§è®­ç»ƒè½®æ•°                â”‚
â”‚  - --gpuï¼šä½¿ç”¨å“ªä¸ª GPU                      â”‚
â”‚  - --test_areaï¼šéªŒè¯åŒºåŸŸï¼ˆ1~6ï¼‰              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤¹å¹¶è®°å½•æ—¥å¿—ï¼š
ğŸ“„ log_train_Area_*.txtï¼ˆæ¯è½®è®°å½• loss / acc / IoUï¼‰

2ï¸âƒ£ æ•°æ®å‡†å¤‡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“¦ æ•°æ®é›†æ„å»ºï¼š                              â”‚
â”‚   dataset = S3DIS(test_area=FLAGS.test_area) â”‚
â”‚ ğŸ“¦ é‡‡æ ·å™¨æ„å»ºï¼š                              â”‚
â”‚   training_dataset = S3DISSampler(dataset, 'training') â”‚
â”‚   validation_dataset = S3DISSampler(dataset, 'validation') â”‚
â”‚ ğŸ“¦ æ•°æ®åŠ è½½å™¨æ„å»ºï¼š                          â”‚
â”‚   training_dataloader = DataLoader(...)      â”‚
â”‚   validation_dataloader = DataLoader(...)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
è¾“å…¥è¾“å‡ºæ•°æ®æ ¼å¼ï¼š
  - è¾“å…¥ï¼šS3DIS åŸå§‹åˆ†å—ç‚¹äº‘ï¼ˆPLY/TXTæ ¼å¼ï¼‰
  - è¾“å‡ºï¼šè®­ç»ƒ/éªŒè¯ç”¨ batch æ•°æ®å­—å…¸ï¼ˆåŒ…å«ç‚¹ã€æ ‡ç­¾ã€é‚»æ¥ç´¢å¼•ï¼‰

3ï¸âƒ£ æ¨¡å‹ä¸ä¼˜åŒ–å™¨åˆå§‹åŒ–
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨¡å‹æ„å»ºï¼š                                   â”‚
â”‚   net = Network(cfg)                         â”‚
â”‚   net.to(device)                             â”‚
â”‚ ä¼˜åŒ–å™¨æ„å»ºï¼š                                 â”‚
â”‚   optimizer = Adam(net.parameters(), lr)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4ï¸âƒ£ åŠ è½½ checkpointï¼ˆå¯é€‰ï¼‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è‹¥æŒ‡å®š checkpoint_path ä¸”æ–‡ä»¶å­˜åœ¨ï¼š         â”‚
â”‚   - åŠ è½½æ¨¡å‹å‚æ•° net.load_state_dict()       â”‚
â”‚   - åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€ optimizer.load_state_dict()â”‚
â”‚   - ç»§ç»­è®­ç»ƒ start_epoch = checkpoint['epoch']â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5ï¸âƒ£ å¼€å§‹è®­ç»ƒ train(start_epoch)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ epoch å¾ªç¯: for epoch in range(start, max)   â”‚
â”‚ â”œâ”€ æ¯è½®è®­ç»ƒ train_one_epoch()                â”‚
â”‚ â”‚   â”œâ”€ æ•°æ®è½¬GPU                              â”‚
â”‚ â”‚   â”œâ”€ å‰å‘ä¼ æ’­ net(batch_data)              â”‚
â”‚ â”‚   â”œâ”€ è®¡ç®— lossã€accã€IoU                   â”‚
â”‚ â”‚   â”œâ”€ åå‘ä¼ æ’­ loss.backward(), optimizer.step() â”‚
â”‚ â”œâ”€ æ¯è½®éªŒè¯ evaluate_one_epoch()            â”‚
â”‚ â”‚   â”œâ”€ ä»… forwardï¼Œè®°å½•éªŒè¯é›† loss/acc/IoU   â”‚
â”‚ â”œâ”€ è‹¥ IoU æå‡åˆ™ä¿å­˜ checkpoint.tar         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6ï¸âƒ£ è¾“å‡ºæ—¥å¿—
 - æ¯ batch æ‰“å° loss / acc / lr / iou
 - æ¯è½®è¾“å‡º mean IoU / æ¯ç±» IoU
 - ä¿å­˜æœ€ä¼˜æ¨¡å‹åˆ° checkpoint.tar

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“ è¾“å…¥è¾“å‡ºæ–‡ä»¶ç±»å‹è¯´æ˜
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ è¾“å…¥æ•°æ®ï¼š
  - .ply / .txtï¼šstep1 é¢„å¤„ç†åçš„ç‚¹äº‘æ–‡ä»¶ï¼ˆå« xyzrgb æˆ– xyzrgb + labelï¼‰
  - .label / .npyï¼šæ ‡ç­¾æ•°æ®ï¼ˆè¯­ä¹‰åˆ†å‰²ç›‘ç£ï¼‰

â€¢ ä¸­é—´ç»“æœï¼š
  - batch_dataï¼šDataLoader è¾“å‡ºçš„è®­ç»ƒ/éªŒè¯æ‰¹æ¬¡æ•°æ®ï¼ˆåŒ…å«ç‚¹ã€æ ‡ç­¾ã€æ©ç ç­‰ï¼‰

â€¢ è¾“å‡ºæ–‡ä»¶ï¼š
  - æ—¥å¿—æ–‡ä»¶ï¼šlog_train_Area_*.txt
  - æ¨¡å‹æ–‡ä»¶ï¼šcheckpoint.tarï¼ˆåŒ…å«ç½‘ç»œæƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“Œ å‡½æ•°æ˜ å°„å…³ç³»ï¼ˆè®­ç»ƒä¸»å¹²ç»“æ„ï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
main() â†’ train(start_epoch)
         â”œâ”€ train_one_epoch()
         â”‚    â”œâ”€ adjust_learning_rate()
         â”‚    â”œâ”€ net.forward()
         â”‚    â”œâ”€ compute_loss()
         â”‚    â”œâ”€ compute_acc()
         â”‚    â””â”€ IoUCalculator.add_data()
         â”œâ”€ evaluate_one_epoch()
         â”‚    â”œâ”€ net.eval(), forward
         â”‚    â”œâ”€ compute_loss(), compute_acc()
         â”‚    â””â”€ IoUCalculator.compute_iou()
         â””â”€ ä¿å­˜ checkpointï¼ˆå¦‚æœ mIoU æœ€ä¼˜ï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ” æ¯è½®è®­ç»ƒè¾“å‡ºç¤ºä¾‹ï¼ˆlog_train_Area_5.txtï¼‰ï¼š
Step 050 Loss 0.238 Acc 82.54 lr 0.00100 --- 227.56 ms/batch
mean IoU: 61.4
IoU: 84.13 49.03 67.24 12.33 56.02 52.08 44.91 86.34 23.19 61.05 84.93 53.26 20.59
Best mIoU = 61.42%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

```

---

##  æ€»ç»“ä¸€å¥è¯

è¯¥è„šæœ¬æ˜¯ RandLA-Net åœ¨ S3DIS ä¸Šçš„å®Œæ•´è®­ç»ƒæ¡†æ¶ï¼ŒåŒ…æ‹¬ **æ•°æ®å‡†å¤‡ã€ç½‘ç»œæ„å»ºã€è®­ç»ƒä¸éªŒè¯æµç¨‹ã€æ€§èƒ½è¯„ä¼°ä¸ä¿å­˜**ã€‚ä½ å¯å°†å…¶ä½œä¸ºä¸»æ§è„šæœ¬ä¸²è”æ‰€æœ‰æµç¨‹æ¨¡å—ã€‚

---
